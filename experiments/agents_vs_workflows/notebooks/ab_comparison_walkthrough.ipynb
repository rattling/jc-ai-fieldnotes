{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84db0fe0",
   "metadata": {},
   "source": [
    "# Agents vs Workflows â€” A/B Walkthrough\n",
    "\n",
    "This notebook runs both orchestration modes on the same sample documents and compares outputs.\n",
    "\n",
    "Use this for exploratory analysis and narrative reporting. Use the CLI for repeatable operational runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b02030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'experiment_dir': '/home/john/repos/jc-ai-fieldnotes/experiments/agents_vs_workflows', 'samples_exists': True}\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "from agents_vs_workflows.workflow.pipeline import run_workflow\n",
    "\n",
    "from agents_vs_workflows.agent.pipeline import run_agentic\n",
    "\n",
    "from agents_vs_workflows.eval.metrics import score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def resolve_experiment_dir() -> Path:\n",
    "\n",
    "    cwd = Path.cwd().resolve()\n",
    "\n",
    "\n",
    "\n",
    "    direct_candidate = cwd / \"experiments\" / \"agents_vs_workflows\"\n",
    "\n",
    "    if (direct_candidate / \"data\" / \"samples.jsonl\").exists():\n",
    "\n",
    "        return direct_candidate\n",
    "\n",
    "\n",
    "\n",
    "    if (cwd / \"data\" / \"samples.jsonl\").exists() and cwd.name == \"agents_vs_workflows\":\n",
    "\n",
    "        return cwd\n",
    "\n",
    "\n",
    "\n",
    "    for base in [cwd, *cwd.parents]:\n",
    "\n",
    "        candidate = base / \"experiments\" / \"agents_vs_workflows\"\n",
    "\n",
    "        if (candidate / \"data\" / \"samples.jsonl\").exists():\n",
    "\n",
    "            return candidate\n",
    "\n",
    "\n",
    "\n",
    "    raise FileNotFoundError(\n",
    "\n",
    "        \"Could not locate experiments/agents_vs_workflows/data/samples.jsonl from current working directory.\"\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "EXPERIMENT_DIR = resolve_experiment_dir()\n",
    "\n",
    "SAMPLES_PATH = EXPERIMENT_DIR / \"data\" / \"samples.jsonl\"\n",
    "\n",
    "GOLD_PATH = EXPERIMENT_DIR / \"data\" / \"gold.jsonl\"\n",
    "\n",
    "print({\"experiment_dir\": str(EXPERIMENT_DIR), \"samples_exists\": SAMPLES_PATH.exists()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6b8339e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_jsonl(path: Path, limit: int | None = None):\n",
    "    rows = []\n",
    "    with path.open('r', encoding='utf-8') as handle:\n",
    "        for line in handle:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            rows.append(json.loads(line))\n",
    "            if limit is not None and len(rows) >= limit:\n",
    "                break\n",
    "    return rows\n",
    "\n",
    "samples = read_jsonl(SAMPLES_PATH, limit=12)\n",
    "gold_rows = read_jsonl(GOLD_PATH)\n",
    "gold_by_id = {row['doc_id']: row for row in gold_rows}\n",
    "len(samples), len(gold_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb5b53a",
   "metadata": {},
   "source": [
    "## Run both modes on identical inputs\n",
    "\n",
    "The key comparison principle is fixed inputs + shared output schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d9af2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow_predictions = []\n",
    "agent_predictions = []\n",
    "\n",
    "for sample in samples:\n",
    "    workflow_predictions.append(run_workflow(sample, max_retries=1).model_dump())\n",
    "    agent_predictions.append(run_agentic(sample, max_tool_calls=6, timeout_ms=2000).model_dump())\n",
    "\n",
    "len(workflow_predictions), len(agent_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4ac4a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'workflow': {'doc_id': 'DOC-0001',\n",
       "   'doc_type': 'security_questionnaire',\n",
       "   'priority': 'P2',\n",
       "   'queue': 'compliance_ops',\n",
       "   'escalate': False,\n",
       "   'missing': ['required_due_date'],\n",
       "   'tool_calls': 0,\n",
       "   'elapsed_ms': 0},\n",
       "  'agent': {'doc_id': 'DOC-0001',\n",
       "   'doc_type': 'security_questionnaire',\n",
       "   'priority': 'P2',\n",
       "   'queue': 'compliance_ops',\n",
       "   'escalate': False,\n",
       "   'missing': ['required_due_date'],\n",
       "   'tool_calls': 3,\n",
       "   'elapsed_ms': 0}},\n",
       " {'workflow': {'doc_id': 'DOC-0002',\n",
       "   'doc_type': 'billing_dispute',\n",
       "   'priority': 'P2',\n",
       "   'queue': 'billing_ops',\n",
       "   'escalate': False,\n",
       "   'missing': ['invoice_id'],\n",
       "   'tool_calls': 0,\n",
       "   'elapsed_ms': 0},\n",
       "  'agent': {'doc_id': 'DOC-0002',\n",
       "   'doc_type': 'billing_dispute',\n",
       "   'priority': 'P2',\n",
       "   'queue': 'billing_ops',\n",
       "   'escalate': False,\n",
       "   'missing': ['invoice_id'],\n",
       "   'tool_calls': 3,\n",
       "   'elapsed_ms': 0}},\n",
       " {'workflow': {'doc_id': 'DOC-0003',\n",
       "   'doc_type': 'incident_report',\n",
       "   'priority': 'P1',\n",
       "   'queue': 'support_incident',\n",
       "   'escalate': True,\n",
       "   'missing': ['request_id_examples'],\n",
       "   'tool_calls': 0,\n",
       "   'elapsed_ms': 0},\n",
       "  'agent': {'doc_id': 'DOC-0003',\n",
       "   'doc_type': 'incident_report',\n",
       "   'priority': 'P1',\n",
       "   'queue': 'support_incident',\n",
       "   'escalate': True,\n",
       "   'missing': ['request_id_examples'],\n",
       "   'tool_calls': 4,\n",
       "   'elapsed_ms': 0}},\n",
       " {'workflow': {'doc_id': 'DOC-0004',\n",
       "   'doc_type': 'access_request',\n",
       "   'priority': 'P2',\n",
       "   'queue': 'security_access',\n",
       "   'escalate': False,\n",
       "   'missing': ['approval_reference'],\n",
       "   'tool_calls': 0,\n",
       "   'elapsed_ms': 0},\n",
       "  'agent': {'doc_id': 'DOC-0004',\n",
       "   'doc_type': 'access_request',\n",
       "   'priority': 'P2',\n",
       "   'queue': 'security_access',\n",
       "   'escalate': False,\n",
       "   'missing': ['approval_reference'],\n",
       "   'tool_calls': 4,\n",
       "   'elapsed_ms': 0}},\n",
       " {'workflow': {'doc_id': 'DOC-0005',\n",
       "   'doc_type': 'feature_request',\n",
       "   'priority': 'P3',\n",
       "   'queue': 'product_feedback',\n",
       "   'escalate': False,\n",
       "   'missing': ['business_justification'],\n",
       "   'tool_calls': 0,\n",
       "   'elapsed_ms': 0},\n",
       "  'agent': {'doc_id': 'DOC-0005',\n",
       "   'doc_type': 'feature_request',\n",
       "   'priority': 'P3',\n",
       "   'queue': 'product_feedback',\n",
       "   'escalate': False,\n",
       "   'missing': ['business_justification'],\n",
       "   'tool_calls': 3,\n",
       "   'elapsed_ms': 0}}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compact(pred):\n",
    "    trace = pred.get('decision_trace', {})\n",
    "    return {\n",
    "        'doc_id': pred['doc_id'],\n",
    "        'doc_type': pred['doc_type'],\n",
    "        'priority': pred['priority'],\n",
    "        'queue': pred['recommended_queue'],\n",
    "        'escalate': pred['escalate'],\n",
    "        'missing': pred['required_missing_fields'],\n",
    "        'tool_calls': trace.get('tool_calls', 0),\n",
    "        'elapsed_ms': trace.get('elapsed_ms', 0),\n",
    "    }\n",
    "\n",
    "[\n",
    "    {'workflow': compact(w), 'agent': compact(a)}\n",
    "    for w, a in zip(workflow_predictions[:5], agent_predictions[:5])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b24fe08",
   "metadata": {},
   "source": [
    "## Compare aggregate metrics (sample subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c79e4abf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'distinct_step_patterns'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m      1\u001b[39m workflow_metrics = score(workflow_predictions, gold_by_id)\n\u001b[32m      3\u001b[39m agent_metrics = score(agent_predictions, gold_by_id)\n\u001b[32m      7\u001b[39m {\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mworkflow\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m     10\u001b[39m \n\u001b[32m     11\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mdoc_type_accuracy\u001b[39m\u001b[33m'\u001b[39m: workflow_metrics[\u001b[33m'\u001b[39m\u001b[33mdoc_type_accuracy\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mqueue_accuracy\u001b[39m\u001b[33m'\u001b[39m: workflow_metrics[\u001b[33m'\u001b[39m\u001b[33mqueue_accuracy\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mescalation_precision\u001b[39m\u001b[33m'\u001b[39m: workflow_metrics[\u001b[33m'\u001b[39m\u001b[33mescalation_precision\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mescalation_recall\u001b[39m\u001b[33m'\u001b[39m: workflow_metrics[\u001b[33m'\u001b[39m\u001b[33mescalation_recall\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     18\u001b[39m \n\u001b[32m     19\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmissing_field_recall\u001b[39m\u001b[33m'\u001b[39m: workflow_metrics[\u001b[33m'\u001b[39m\u001b[33mmissing_field_recall\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     20\u001b[39m \n\u001b[32m     21\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mavg_elapsed_ms\u001b[39m\u001b[33m'\u001b[39m: workflow_metrics[\u001b[33m'\u001b[39m\u001b[33mavg_elapsed_ms\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mavg_tool_calls\u001b[39m\u001b[33m'\u001b[39m: workflow_metrics[\u001b[33m'\u001b[39m\u001b[33mavg_tool_calls\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     24\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mdistinct_step_patterns\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mworkflow_metrics\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdistinct_step_patterns\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[32m     26\u001b[39m \n\u001b[32m     27\u001b[39m     },\n\u001b[32m     28\u001b[39m \n\u001b[32m     29\u001b[39m     \u001b[33m'\u001b[39m\u001b[33magent\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m     30\u001b[39m \n\u001b[32m     31\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mdoc_type_accuracy\u001b[39m\u001b[33m'\u001b[39m: agent_metrics[\u001b[33m'\u001b[39m\u001b[33mdoc_type_accuracy\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     32\u001b[39m \n\u001b[32m     33\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mqueue_accuracy\u001b[39m\u001b[33m'\u001b[39m: agent_metrics[\u001b[33m'\u001b[39m\u001b[33mqueue_accuracy\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     34\u001b[39m \n\u001b[32m     35\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mescalation_precision\u001b[39m\u001b[33m'\u001b[39m: agent_metrics[\u001b[33m'\u001b[39m\u001b[33mescalation_precision\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     36\u001b[39m \n\u001b[32m     37\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mescalation_recall\u001b[39m\u001b[33m'\u001b[39m: agent_metrics[\u001b[33m'\u001b[39m\u001b[33mescalation_recall\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     38\u001b[39m \n\u001b[32m     39\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmissing_field_recall\u001b[39m\u001b[33m'\u001b[39m: agent_metrics[\u001b[33m'\u001b[39m\u001b[33mmissing_field_recall\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     40\u001b[39m \n\u001b[32m     41\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mavg_elapsed_ms\u001b[39m\u001b[33m'\u001b[39m: agent_metrics[\u001b[33m'\u001b[39m\u001b[33mavg_elapsed_ms\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     42\u001b[39m \n\u001b[32m     43\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mavg_tool_calls\u001b[39m\u001b[33m'\u001b[39m: agent_metrics[\u001b[33m'\u001b[39m\u001b[33mavg_tool_calls\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     44\u001b[39m \n\u001b[32m     45\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mdistinct_step_patterns\u001b[39m\u001b[33m'\u001b[39m: agent_metrics[\u001b[33m'\u001b[39m\u001b[33mdistinct_step_patterns\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     46\u001b[39m \n\u001b[32m     47\u001b[39m     },\n\u001b[32m     48\u001b[39m \n\u001b[32m     49\u001b[39m }\n",
      "\u001b[31mKeyError\u001b[39m: 'distinct_step_patterns'"
     ]
    }
   ],
   "source": [
    "workflow_metrics = score(workflow_predictions, gold_by_id)\n",
    "\n",
    "agent_metrics = score(agent_predictions, gold_by_id)\n",
    "\n",
    "\n",
    "\n",
    "{\n",
    "\n",
    "    'workflow': {\n",
    "\n",
    "        'doc_type_accuracy': workflow_metrics['doc_type_accuracy'],\n",
    "\n",
    "        'queue_accuracy': workflow_metrics['queue_accuracy'],\n",
    "\n",
    "        'escalation_precision': workflow_metrics['escalation_precision'],\n",
    "\n",
    "        'escalation_recall': workflow_metrics['escalation_recall'],\n",
    "\n",
    "        'missing_field_recall': workflow_metrics['missing_field_recall'],\n",
    "\n",
    "        'avg_elapsed_ms': workflow_metrics['avg_elapsed_ms'],\n",
    "\n",
    "        'avg_tool_calls': workflow_metrics['avg_tool_calls'],\n",
    "\n",
    "        'distinct_step_patterns': workflow_metrics['distinct_step_patterns'],\n",
    "\n",
    "    },\n",
    "\n",
    "    'agent': {\n",
    "\n",
    "        'doc_type_accuracy': agent_metrics['doc_type_accuracy'],\n",
    "\n",
    "        'queue_accuracy': agent_metrics['queue_accuracy'],\n",
    "\n",
    "        'escalation_precision': agent_metrics['escalation_precision'],\n",
    "\n",
    "        'escalation_recall': agent_metrics['escalation_recall'],\n",
    "\n",
    "        'missing_field_recall': agent_metrics['missing_field_recall'],\n",
    "\n",
    "        'avg_elapsed_ms': agent_metrics['avg_elapsed_ms'],\n",
    "\n",
    "        'avg_tool_calls': agent_metrics['avg_tool_calls'],\n",
    "\n",
    "        'distinct_step_patterns': agent_metrics['distinct_step_patterns'],\n",
    "\n",
    "    },\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277f85df",
   "metadata": {},
   "source": [
    "## Suggested interpretation prompts\n",
    "\n",
    "\n",
    "\n",
    "- Where does agent mode improve recall on missing-field detection?\n",
    "\n",
    "- Are escalation precision/recall shifts acceptable for ops policy?\n",
    "\n",
    "- How much latency/tool-call overhead appears in agent mode?\n",
    "\n",
    "- Which doc types show the largest quality delta?\n",
    "\n",
    "- If quality metrics are equal, compare structural behavior (`distinct_step_patterns`, `avg_tool_calls`) to verify dynamic vs fixed orchestration differences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jc-ai-fieldnotes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
